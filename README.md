# PySpark

Apache Spark + Python = PySpark (for processing large volume of data in distrubuted manner)

Here we gonna upload PySpark running on a single node (in a single machine instead of multiple machine) and standalone mode (only spark not hadoop).

